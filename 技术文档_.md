# 快速上手: AI模型预测分子活性（基于Dflow工作流套件）

## Prerequisite
1. 预装Anaconda3
2. 预置海外节点（此处感谢纽约大学的海外节点及计算资源）
3. 下载文件: 
- 快速Setup脚本
    - install-linux.sh 或 
    - install-mac.sh
- Hello World 快速入门notebook
    - 基于ShellOPTemplate
    - 基于PythonOPTemplate
    - 四步入门AI模型预测分子活性

## Quick Setup (MacOS)
Note: 每一次开机后都需要进行一次Setup过程。配置完毕后方可多次提交工作流。


```python
import platform
import subprocess
```

### Detect os env


```python
def detect_os():
    os_name = platform.system()
    if os_name in ["Darwin","Linux"]:
        return os_name
    else:
        return "Unknown OS"
```


```python
os_name = detect_os()
print(os_name)
```

    Darwin


### Bash setup script


```python
def setup_dflow(os_name, os_env="notebook"):
    """
    Executes an installation script based on the provided operating system name.
    """
    # Setting the script path based on the operating system
    if os_name == "Darwin":
        script_path = "install-mac.sh"
    elif os_name == "Linux":
        script_path = "install-linux.sh"
    else:
        return "Unsupported OS for this operation"

    # Executing the script
    try:
        if os_env != "notebook":
            result = subprocess.run(['bash', script_path], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            return result.stdout.decode('utf-8')
        else:
            get_ipython().system(f'bash {script_path}')
            return "Done."
    except subprocess.CalledProcessError as e:
        return f"An error occurred: {e.stderr.decode('utf-8')}"
```


```python
# Example usage:
output = setup_dflow(os_name)
print(output)
```

    [INFO] Found docker client at /opt/homebrew/bin/docker
    [INFO] Docker server has been running
    [INFO] Found minikube binary at /usr/local/bin/minikube
    [INFO] Minikube has been started
    ^C
    Done.


显示如下字样即表示成功：
```
[INFO] Found docker client at /opt/homebrew/bin/docker
[INFO] Docker server has been running
[INFO] Found minikube binary at /usr/local/bin/minikube
[INFO] Minikube has been started
[INFO] argo-server has been ready...
[INFO] minio has been ready...
[INFO] postgres has been ready...
[INFO] workflow-controller has been ready...
[INFO] Forwarding argo-server:2746 to localhost:2746
appending output to nohup.out
[INFO] Forwarding minio:9000 to localhost:9000
appending output to nohup.out
[INFO] Forwarding minio:9001 to localhost:9001
appending output to nohup.out
[INFO] dflow server has been installed successfully!
```

## Hello world Example 1: 基于ShellOPTemplate


```python
from dflow import (
    ShellOPTemplate,
    upload_artifact,
    InputParameter, InputArtifact,
    OutputParameter, OutputArtifact,
    Step,
    Workflow
    )
```


```python
art = upload_artifact("foo.txt")
```


```python
step1_templ = ShellOPTemplate(
    name="Hello",
    image="alpine:latest",
    script="echo {{inputs.parameters.msg}} > /tmp/msg.txt && echo {{inputs.parameters.number}} > /tmp/results.txt",
)
step1_templ.inputs.parameters = {
    "msg": InputParameter(),
    "number": InputParameter(),
}
step1_templ.inputs.artifacts = {
    "in_art": InputArtifact(path="msg.txt")
}
step1_templ.outputs.parameters = {
    "out_param": OutputParameter(value_from_path="/tmp/results.txt")
}
step1_templ.outputs.artifacts = {
    "out_art": OutputArtifact(path="/tmp/msg.txt")
}
```


```python
step2_templ = ShellOPTemplate(
    name="Duplicate",
    image="alpine:latest",
    script="cat /tmp/foo.txt /tmp/foo.txt > /tmp/bar.txt && echo $(({{inputs.parameters.number}}*2)) > /tmp/results.txt",
)
step2_templ.inputs.artifacts = {
    "in_art":InputArtifact(path="/tmp/foo.txt")
    }
step2_templ.inputs.parameters = {
    "number": InputParameter(),
    }
step2_templ.outputs.artifacts = {
    "out_art": OutputArtifact(path="/tmp/bar.txt")
    }
step2_templ.outputs.parameters = {
    "out_param": OutputParameter(value_from_path="/tmp/results.txt")
    }
```


```python
step1 = Step(
    name="step1",
    template=step1_templ,
    parameters={
        "msg":"HelloWorld!",
        "number": 1,
        },
    artifacts={"in_art": art}
    )
step2 = Step(
    name="step2",
    template=step2_templ,
    parameters={"number":step1.outputs.parameters["out_param"]},
    artifacts={"in_art":step1.outputs.artifacts["out_art"]},
    )
```


```python
wf = Workflow(name="helloworld")
wf.add(step1)
wf.add(step2)
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
wf.submit()
```

    Workflow has been submitted (ID: helloworld-9cbv7, UID: b87fb710-a99d-4722-abb4-8f1158130757)
    Workflow link: https://127.0.0.1:2746/workflows/argo/helloworld-9cbv7





    {'metadata': {'name': 'helloworld-9cbv7', 'generateName': 'helloworld-', 'namespace': 'argo', 'uid': 'b87fb710-a99d-4722-abb4-8f1158130757', 'resourceVersion': '246488', 'generation': 1, 'creationTimestamp': '2024-01-14T10:42:12Z', 'labels': {'workflows.argoproj.io/creator': 'system-serviceaccount-argo-argo-server'}, 'managedFields': [{'manager': 'argo', 'operation': 'Update', 'apiVersion': 'argoproj.io/v1alpha1', 'time': '2024-01-14T10:42:12Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:generateName': {}, 'f:labels': {'.': {}, 'f:workflows.argoproj.io/creator': {}}}, 'f:spec': {}, 'f:status': {}}}]}, 'spec': {'templates': [{'name': 'helloworld-steps', 'inputs': {}, 'outputs': {}, 'metadata': {}, 'steps': [[{'name': 'step1', 'template': 'hello', 'arguments': {'parameters': [{'name': 'msg', 'value': 'HelloWorld!'}, {'name': 'number', 'value': '1'}], 'artifacts': [{'name': 'in_art', 'path': 'msg.txt', 's3': {'key': 'upload/b15948fc-78f6-4f14-8a49-efad7945cb97/tmp3e2dvpbw.tgz'}}]}, 'continueOn': {}}], [{'name': 'step2', 'template': 'duplicate', 'arguments': {'parameters': [{'name': 'number', 'value': "{{=steps['step1'].outputs.parameters['out_param']}}"}], 'artifacts': [{'name': 'in_art', 'path': '/tmp/foo.txt', 'from': '{{steps.step1.outputs.artifacts.out_art}}'}]}, 'continueOn': {}}]]}, {'name': 'hello', 'inputs': {'parameters': [{'name': 'msg'}, {'name': 'number'}], 'artifacts': [{'name': 'in_art', 'path': 'msg.txt'}]}, 'outputs': {'parameters': [{'name': 'out_param', 'valueFrom': {'path': '/tmp/results.txt'}}], 'artifacts': [{'name': 'out_art', 'path': '/tmp/msg.txt'}]}, 'metadata': {'annotations': {'workflows.argoproj.io/progress': '0/1'}}, 'script': {'name': '', 'image': 'alpine:latest', 'command': ['sh'], 'resources': {}, 'source': 'echo {{inputs.parameters.msg}} > /tmp/msg.txt && echo {{inputs.parameters.number}} > /tmp/results.txt'}}, {'name': 'duplicate', 'inputs': {'parameters': [{'name': 'number'}], 'artifacts': [{'name': 'in_art', 'path': '/tmp/foo.txt'}]}, 'outputs': {'parameters': [{'name': 'out_param', 'valueFrom': {'path': '/tmp/results.txt'}}], 'artifacts': [{'name': 'out_art', 'path': '/tmp/bar.txt'}]}, 'metadata': {'annotations': {'workflows.argoproj.io/progress': '0/1'}}, 'script': {'name': '', 'image': 'alpine:latest', 'command': ['sh'], 'resources': {}, 'source': 'cat /tmp/foo.txt /tmp/foo.txt > /tmp/bar.txt && echo $(({{inputs.parameters.number}}*2)) > /tmp/results.txt'}}], 'entrypoint': 'helloworld-steps', 'arguments': {}, 'serviceAccountName': 'argo', 'podGC': {}}, 'status': {'startedAt': None, 'finishedAt': None}, 'id': 'helloworld-9cbv7', 'uid': 'b87fb710-a99d-4722-abb4-8f1158130757'}



## Hello world example 2: 基于PythonOPTemplate


```python
from pathlib import Path

from dflow import Step, Workflow
from dflow.python import OP, OPIO, Artifact, OPIOSign, PythonOPTemplate
```


```python
from dflow import upload_artifact

art = upload_artifact("foo.txt")
print(art)
```

    {'access_key': 'admin',
     'bucket_name': 'my-bucket',
     'console': 'http://127.0.0.1:9001',
     'endpoint': '127.0.0.1:9000',
     'extra_prefixes': [],
     'key': 'upload/b3b58b17-3631-4f0b-874a-290effdb1dd9/tmph0a8luu7.tgz',
     'prefix': '',
     'repo': None,
     'repo_key': None,
     'repo_prefix': '',
     'repo_type': 's3',
     'secret_key': 'password',
     'secure': False,
     'slice': None,
     'storage_client': None,
     'urn': ''}



```python
class WriteFile(OP):
    def __init__(self):
        pass

    @classmethod
    def get_input_sign(cls):
        return OPIOSign({
            "msg": str,
            "foo": Artifact(Path)
        })

    @classmethod
    def get_output_sign(cls):
        return OPIOSign({
            "out_art": Artifact(Path),
            "length": int
        })

    @OP.exec_sign_check
    def execute(
            self,
            op_in: OPIO,
    ) -> OPIO:

        op_out = OPIO({
            "out_art": op_in["foo"],
            "length": len(op_in["msg"])
        })
        return op_out
```


```python
class Duplicate(OP):
    def __init__(self):
        pass

    @classmethod
    def get_input_sign(cls):
        return OPIOSign({
            "in_art": Artifact(Path),
            "in_num": int
        })

    @classmethod
    def get_output_sign(cls):
        return OPIOSign({
            "out_art": Artifact(Path),
            "out_num": int,
        })

    @OP.exec_sign_check
    def execute(
            self,
            op_in: OPIO,
    ) -> OPIO:
        with open(op_in["in_art"], "r") as f:
            content = f.read()
        with open("bar.txt", "w") as f:
            f.write(content * 3)

        op_out = OPIO({
            "out_art": Path("bar.py"),
            "out_num": op_in["in_num"] * 2,
        })
        return op_out
```


```python
import sys
step0 = Step(
    name="step0",
    template=PythonOPTemplate(
        WriteFile, 
        image=f"python:{sys.version_info.major}.{sys.version_info.minor}"
        ),
    parameters={"msg": "HelloWorld!"},
    artifacts={"foo":art}
)

step1 = Step(
    name="step1",
    template=PythonOPTemplate(Duplicate, image=f"python:{sys.version_info.major}.{sys.version_info.minor}"),
    parameters={"in_num": step0.outputs.parameters["length"]},
    artifacts={"in_art": step0.outputs.artifacts["out_art"]},
)
wf = Workflow(name="python")
wf.add(step0)
wf.add(step1)
wf.submit()
```

    Workflow has been submitted (ID: python-lccm6, UID: ae5e6d1f-42ed-4656-b705-48449c4f8d7e)
    Workflow link: https://127.0.0.1:2746/workflows/argo/python-lccm6





    {'metadata': {'name': 'python-lccm6', 'generateName': 'python-', 'namespace': 'argo', 'uid': 'ae5e6d1f-42ed-4656-b705-48449c4f8d7e', 'resourceVersion': '246760', 'generation': 1, 'creationTimestamp': '2024-01-14T10:45:43Z', 'labels': {'workflows.argoproj.io/creator': 'system-serviceaccount-argo-argo-server'}, 'managedFields': [{'manager': 'argo', 'operation': 'Update', 'apiVersion': 'argoproj.io/v1alpha1', 'time': '2024-01-14T10:45:43Z', 'fieldsType': 'FieldsV1', 'fieldsV1': {'f:metadata': {'f:generateName': {}, 'f:labels': {'.': {}, 'f:workflows.argoproj.io/creator': {}}}, 'f:spec': {}, 'f:status': {}}}]}, 'spec': {'templates': [{'name': 'python-steps', 'inputs': {}, 'outputs': {}, 'metadata': {}, 'steps': [[{'name': 'step0', 'template': 'writefile-pvoee', 'arguments': {'parameters': [{'name': 'msg', 'value': 'HelloWorld!', 'description': '{"type": "str"}'}], 'artifacts': [{'name': 'foo', 'path': '/tmp/inputs/artifacts/foo', 's3': {'key': 'upload/b3b58b17-3631-4f0b-874a-290effdb1dd9/tmph0a8luu7.tgz'}}, {'name': 'dflow_python_packages', 'path': '/tmp/inputs/artifacts/dflow_python_packages', 's3': {'key': 'upload/7457f40a-111f-4b6d-b25c-7ff3005fe5e7/tmpvvrv_gym.tgz'}}]}, 'continueOn': {}}], [{'name': 'step1', 'template': 'duplicate-mpx7w', 'arguments': {'parameters': [{'name': 'in_num', 'value': "{{=steps['step0'].outputs.parameters['length']}}", 'description': '{"type": "int"}'}], 'artifacts': [{'name': 'in_art', 'path': '/tmp/inputs/artifacts/in_art', 'from': '{{steps.step0.outputs.artifacts.out_art}}'}, {'name': 'dflow_python_packages', 'path': '/tmp/inputs/artifacts/dflow_python_packages', 's3': {'key': 'upload/7457f40a-111f-4b6d-b25c-7ff3005fe5e7/tmpvvrv_gym.tgz'}}]}, 'continueOn': {}}]]}, {'name': 'writefile-pvoee', 'inputs': {'parameters': [{'name': 'msg', 'description': '{"type": "str"}'}], 'artifacts': [{'name': 'foo', 'path': '/tmp/inputs/artifacts/foo'}, {'name': 'dflow_python_packages', 'path': '/tmp/inputs/artifacts/dflow_python_packages'}]}, 'outputs': {'parameters': [{'name': 'length', 'valueFrom': {'path': '/tmp/outputs/parameters/length', 'default': 'null'}, 'description': '{"type": "int"}'}], 'artifacts': [{'name': 'out_art', 'path': '/tmp/outputs/artifacts/out_art'}]}, 'metadata': {'annotations': {'workflows.argoproj.io/progress': '0/1'}}, 'script': {'name': '', 'image': 'python:3.11', 'command': ['python3'], 'resources': {}, 'source': 'import os, sys, json\npackage_root = r\'/tmp/inputs/artifacts/dflow_python_packages\'\ncatalog_dir = os.path.join(package_root, \'.dflow\')\nif os.path.exists(catalog_dir):\n    for f in os.listdir(catalog_dir):\n        with open(os.path.join(catalog_dir, f), \'r\') as fd:\n            for item in json.load(fd)[\'path_list\']:\n                path = os.path.join(package_root, os.path.dirname(item[\'dflow_list_item\']))\n                sys.path.insert(0, path)\n                os.environ[\'PYTHONPATH\'] = path + \':\' + os.environ.get(\'PYTHONPATH\', \'\')\nimport json, jsonpickle\nfrom dflow import config, s3_config\nconfig.update(jsonpickle.loads(r\'\'\'{"host": "https://127.0.0.1:2746", "namespace": "argo", "token": null, "k8s_config_file": null, "k8s_api_server": null, "private_key_host_path": null, "save_path_as_parameter": false, "catalog_dir_name": ".dflow", "archive_mode": "tar", "util_image": "python:3.8", "util_image_pull_policy": null, "extender_image": "dptechnology/dflow-extender", "extender_image_pull_policy": null, "dispatcher_image": "dptechnology/dpdispatcher", "dispatcher_image_pull_policy": null, "save_keys_in_global_outputs": true, "mode": "default", "lineage": null, "register_tasks": false, "http_headers": {}, "workflow_annotations": {}, "overwrite_reused_artifact": true, "detach": false, "debug_copy_method": "symlink", "debug_pool_workers": null, "debug_batch_size": null, "debug_batch_interval": 30, "detect_empty_dir": true, "artifact_register": {}, "debug_s3": false, "debug_workdir": ".", "debug_artifact_dir": "."}\'\'\'))\ns3_config.update(jsonpickle.loads(r\'\'\'{"endpoint": "127.0.0.1:9000", "console": "http://127.0.0.1:9001", "access_key": "admin", "secret_key": "password", "secure": false, "bucket_name": "my-bucket", "repo_key": null, "repo": null, "repo_type": "s3", "repo_prefix": "", "prefix": "", "storage_client": null, "extra_prefixes": []}\'\'\'))\nimport cloudpickle\nWriteFile = cloudpickle.loads(b\'\\x80\\x05\\x95$\\n\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x17cloudpickle.cloudpickle\\x94\\x8c\\x14_make_skeleton_class\\x94\\x93\\x94(\\x8c\\x03abc\\x94\\x8c\\x07ABCMeta\\x94\\x93\\x94\\x8c\\tWriteFile\\x94\\x8c\\x0fdflow.python.op\\x94\\x8c\\x02OP\\x94\\x93\\x94\\x85\\x94}\\x94\\x8c 960f1fe4143c4fbfb5b7a7893bf70373\\x94Nt\\x94R\\x94\\x8c\\x1ccloudpickle.cloudpickle_fast\\x94\\x8c\\x0f_class_setstate\\x94\\x93\\x94h\\x0e}\\x94(\\x8c\\n__module__\\x94\\x8c\\x08__main__\\x94\\x8c\\x08__init__\\x94h\\x00\\x8c\\x0e_make_function\\x94\\x93\\x94(h\\x00\\x8c\\r_builtin_type\\x94\\x93\\x94\\x8c\\x08CodeType\\x94\\x85\\x94R\\x94(K\\x01K\\x00K\\x00K\\x01K\\x01K\\x03C\\x06\\x97\\x00d\\x00S\\x00\\x94N\\x85\\x94)\\x8c\\x04self\\x94\\x85\\x94\\x8cN/var/folders/v7/0mwcqlzd0c56flv47rkmgwj80000gp/T/ipykernel_95080/2172636019.py\\x94h\\x15\\x8c\\x12WriteFile.__init__\\x94K\\x02C\\x07\\x80\\x00\\xd8\\x08\\x0c\\x88\\x04\\x94C\\x00\\x94))t\\x94R\\x94}\\x94(\\x8c\\x0b__package__\\x94N\\x8c\\x08__name__\\x94h\\x14uNNNt\\x94R\\x94h\\x0f\\x8c\\x12_function_setstate\\x94\\x93\\x94h+}\\x94}\\x94(h)h\\x15\\x8c\\x0c__qualname__\\x94h"\\x8c\\x0f__annotations__\\x94}\\x94\\x8c\\x0e__kwdefaults__\\x94N\\x8c\\x0c__defaults__\\x94Nh\\x13h\\x14\\x8c\\x07__doc__\\x94N\\x8c\\x0b__closure__\\x94N\\x8c\\x17_cloudpickle_submodules\\x94]\\x94\\x8c\\x0b__globals__\\x94}\\x94u\\x86\\x94\\x86R0\\x8c\\x0eget_input_sign\\x94\\x8c\\x08builtins\\x94\\x8c\\x0bclassmethod\\x94\\x93\\x94h\\x17(h\\x1c(K\\x01K\\x00K\\x00K\\x01K\\x06K\\x03CT\\x97\\x00t\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x05\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x01\\x9c\\x02\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00S\\x00\\x94N\\x8c\\x03msg\\x94\\x8c\\x03foo\\x94\\x86\\x94\\x86\\x94(\\x8c\\x08OPIOSign\\x94\\x8c\\x03str\\x94\\x8c\\x08Artifact\\x94\\x8c\\x04Path\\x94t\\x94\\x8c\\x03cls\\x94\\x85\\x94h!h<\\x8c\\x18WriteFile.get_input_sign\\x94K\\x05C*\\x80\\x00\\xe5\\x0f\\x17\\xdd\\x13\\x16\\xdd\\x13\\x1b\\x9dD\\x91>\\x94>\\xf0\\x05\\x03\\x19\\n\\xf0\\x00\\x03\\x19\\n\\xf1\\x00\\x03\\x10\\x0b\\xf4\\x00\\x03\\x10\\x0b\\xf0\\x00\\x03\\t\\x0b\\x94h$))t\\x94R\\x94h\\\'NNNt\\x94R\\x94h-hQ}\\x94}\\x94(h)h<h0hLh1}\\x94h3Nh4Nh\\x13h\\x14h5Nh6Nh7]\\x94h9}\\x94(hE\\x8c\\x11dflow.python.opio\\x94hE\\x93\\x94hGhWhG\\x93\\x94hH\\x8c\\x07pathlib\\x94hH\\x93\\x94uu\\x86\\x94\\x86R0\\x85\\x94R\\x94\\x8c\\x0fget_output_sign\\x94h?h\\x17(h\\x1c(K\\x01K\\x00K\\x00K\\x01K\\x05K\\x03CT\\x97\\x00t\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x01\\x9c\\x02\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00S\\x00\\x94N\\x8c\\x07out_art\\x94\\x8c\\x06length\\x94\\x86\\x94\\x86\\x94(hEhGhH\\x8c\\x03int\\x94t\\x94hJ\\x85\\x94h!h_\\x8c\\x19WriteFile.get_output_sign\\x94K\\x0cC*\\x80\\x00\\xe5\\x0f\\x17\\xdd\\x17\\x1f\\xa5\\x04\\x91~\\x94~\\xdd\\x16\\x19\\xf0\\x05\\x03\\x19\\n\\xf0\\x00\\x03\\x19\\n\\xf1\\x00\\x03\\x10\\x0b\\xf4\\x00\\x03\\x10\\x0b\\xf0\\x00\\x03\\t\\x0b\\x94h$))t\\x94R\\x94h\\\'NNNt\\x94R\\x94h-hm}\\x94}\\x94(h)h_h0hhh1}\\x94h3Nh4Nh\\x13h\\x14h5Nh6Nh7]\\x94h9}\\x94(hEhXhGhYhHh[uu\\x86\\x94\\x86R0\\x85\\x94R\\x94\\x8c\\x07execute\\x94h\\x17(h\\x1c(K\\x02K\\x00K\\x00K\\x03K\\x05K\\x13C\\xd8\\x95\\x01\\x97\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa0\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x01|\\x00\\xa0\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa6\\x00\\x00\\x00\\xab\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x01\\xa6\\x03\\x00\\x00\\xab\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x89\\x03|\\x00|\\x01\\xa6\\x02\\x00\\x00\\xab\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x02t\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa0\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x02|\\x00\\xa0\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa6\\x00\\x00\\x00\\xab\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x02\\xa6\\x03\\x00\\x00\\xab\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00|\\x02S\\x00\\x94N\\x88\\x89\\x87\\x94(h\\x08\\x8c\\x10_check_signature\\x94h<h_t\\x94h\\x1f\\x8c\\x05op_in\\x94\\x8c\\x06op_out\\x94\\x87\\x94\\x8cE/Users/star/anaconda3/lib/python3.11/site-packages/dflow/python/op.py\\x94\\x8c\\x0cwrapper_exec\\x94\\x8c(OP.exec_sign_check.<locals>.wrapper_exec\\x94K\\x85Ca\\xf8\\x80\\x00\\xe5\\x0c\\x0e\\xd7\\x0c\\x1f\\xd2\\x0c\\x1f\\xa0\\x05\\xa0t\\xd7\\\':\\xd2\\\':\\xd1\\\'<\\xd4\\\'<\\xb8d\\xd1\\x0cC\\xd4\\x0cC\\xd0\\x0cC\\xd8\\x15\\x19\\x90T\\x98$\\xa0\\x05\\xd1\\x15&\\xd4\\x15&\\x88F\\xdd\\x0c\\x0e\\xd7\\x0c\\x1f\\xd2\\x0c\\x1f\\xa0\\x06\\xa8\\x04\\xd7(<\\xd2(<\\xd1(>\\xd4(>\\xc0\\x05\\xd1\\x0cF\\xd4\\x0cF\\xd0\\x0cF\\xd8\\x13\\x19\\x88M\\x94h$\\x8c\\x04func\\x94\\x85\\x94)t\\x94R\\x94}\\x94(h(\\x8c\\x0cdflow.python\\x94h)h\\x07\\x8c\\x08__file__\\x94\\x8cE/Users/star/anaconda3/lib/python3.11/site-packages/dflow/python/op.py\\x94uNNh\\x00\\x8c\\x10_make_empty_cell\\x94\\x93\\x94)R\\x94\\x85\\x94t\\x94R\\x94h-h\\x8f}\\x94\\x8c\\x0b__wrapped__\\x94h\\x17(h\\x1c(K\\x02K\\x00K\\x00K\\x03K\\x07K\\x03C\\\\\\x97\\x00t\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x01d\\x01\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x01d\\x02\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x03\\x9c\\x02\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x02|\\x02S\\x00\\x94(NhBhAhct\\x94\\x8c\\x04OPIO\\x94\\x8c\\x03len\\x94\\x86\\x94h\\x1fh{h|\\x87\\x94h!hv\\x8c\\x11WriteFile.execute\\x94K\\x13C:\\x80\\x00\\xf5\\x0c\\x00\\x12\\x16\\xd8\\x17\\x1c\\x98U\\x94|\\xdd\\x16\\x19\\x98%\\xa0\\x05\\x9c,\\xd1\\x16\\\'\\xd4\\x16\\\'\\xf0\\x05\\x03\\x17\\n\\xf0\\x00\\x03\\x17\\n\\xf1\\x00\\x03\\x12\\x0b\\xf4\\x00\\x03\\x12\\x0b\\x88\\x06\\xf0\\x08\\x00\\x10\\x16\\x88\\r\\x94h$))t\\x94R\\x94h\\\'NNNt\\x94R\\x94h-h\\x9d}\\x94}\\x94(h)hvh0h\\x98h1}\\x94(h{hWh\\x94\\x93\\x94\\x8c\\x06return\\x94h\\xa1uh3Nh4Nh\\x13h\\x14h5Nh6Nh7]\\x94h9}\\x94h\\x94h\\xa1su\\x86\\x94\\x86R0s}\\x94(h)hvh0h\\x98h1h\\xa0h3Nh4Nh\\x13h\\x14h5Nh6h\\x00\\x8c\\n_make_cell\\x94\\x93\\x94h\\x9d\\x85\\x94R\\x94\\x85\\x94h7]\\x94h9}\\x94h\\x08h\\tsu\\x86\\x94\\x86R0h5N\\x8c\\x13__abstractmethods__\\x94(\\x91\\x94\\x8c\\t_abc_impl\\x94]\\x94u}\\x94\\x86\\x94\\x86R0.\')\nimport os, sys, traceback, jsonpickle\nfrom dflow.python import OPIO, TransientError, FatalError\nfrom dflow.python.utils import handle_input_artifact, handle_input_parameter\nfrom dflow.python.utils import handle_output_artifact, handle_output_parameter, handle_lineage\nfrom __main__ import WriteFile\n\nop_obj = WriteFile()\nop_obj.key = \'{{=inputs.parameters.dflow_key}}\'\nif op_obj.key.startswith(\'{\'): op_obj.key = None\nop_obj.workflow_name = \'{{workflow.name}}\'\nif __name__ == \'__main__\':\n    input = OPIO()\n    input_sign = WriteFile.get_input_sign()\n    output_sign = WriteFile.get_output_sign()\n    input[\'msg\'] = handle_input_parameter(\'msg\', r\'\'\'{{inputs.parameters.msg}}\'\'\', input_sign[\'msg\'], None, r\'/tmp\')\n    input[\'foo\'] = handle_input_artifact(\'foo\', input_sign[\'foo\'], None, r\'/tmp\', None, n_parts=None, keys_of_parts=None, prefix=None)\n    try:\n        output = op_obj.execute(input)\n    except TransientError:\n        traceback.print_exc()\n        sys.exit(1)\n    except FatalError:\n        traceback.print_exc()\n        sys.exit(2)\n    os.makedirs(r\'/tmp/outputs/parameters\', exist_ok=True)\n    os.makedirs(r\'/tmp/outputs/artifacts\', exist_ok=True)\n    handle_output_artifact(\'out_art\', output[\'out_art\'], output_sign[\'out_art\'], None, r\'/tmp\')\n    handle_output_parameter(\'length\', output[\'length\'], output_sign[\'length\'], None, r\'/tmp\')\n'}}, {'name': 'duplicate-mpx7w', 'inputs': {'parameters': [{'name': 'in_num', 'description': '{"type": "int"}'}], 'artifacts': [{'name': 'in_art', 'path': '/tmp/inputs/artifacts/in_art'}, {'name': 'dflow_python_packages', 'path': '/tmp/inputs/artifacts/dflow_python_packages'}]}, 'outputs': {'parameters': [{'name': 'out_num', 'valueFrom': {'path': '/tmp/outputs/parameters/out_num', 'default': 'null'}, 'description': '{"type": "int"}'}], 'artifacts': [{'name': 'out_art', 'path': '/tmp/outputs/artifacts/out_art'}]}, 'metadata': {'annotations': {'workflows.argoproj.io/progress': '0/1'}}, 'script': {'name': '', 'image': 'python:3.11', 'command': ['python3'], 'resources': {}, 'source': 'import os, sys, json\npackage_root = r\'/tmp/inputs/artifacts/dflow_python_packages\'\ncatalog_dir = os.path.join(package_root, \'.dflow\')\nif os.path.exists(catalog_dir):\n    for f in os.listdir(catalog_dir):\n        with open(os.path.join(catalog_dir, f), \'r\') as fd:\n            for item in json.load(fd)[\'path_list\']:\n                path = os.path.join(package_root, os.path.dirname(item[\'dflow_list_item\']))\n                sys.path.insert(0, path)\n                os.environ[\'PYTHONPATH\'] = path + \':\' + os.environ.get(\'PYTHONPATH\', \'\')\nimport json, jsonpickle\nfrom dflow import config, s3_config\nconfig.update(jsonpickle.loads(r\'\'\'{"host": "https://127.0.0.1:2746", "namespace": "argo", "token": null, "k8s_config_file": null, "k8s_api_server": null, "private_key_host_path": null, "save_path_as_parameter": false, "catalog_dir_name": ".dflow", "archive_mode": "tar", "util_image": "python:3.8", "util_image_pull_policy": null, "extender_image": "dptechnology/dflow-extender", "extender_image_pull_policy": null, "dispatcher_image": "dptechnology/dpdispatcher", "dispatcher_image_pull_policy": null, "save_keys_in_global_outputs": true, "mode": "default", "lineage": null, "register_tasks": false, "http_headers": {}, "workflow_annotations": {}, "overwrite_reused_artifact": true, "detach": false, "debug_copy_method": "symlink", "debug_pool_workers": null, "debug_batch_size": null, "debug_batch_interval": 30, "detect_empty_dir": true, "artifact_register": {}, "debug_s3": false, "debug_workdir": ".", "debug_artifact_dir": "."}\'\'\'))\ns3_config.update(jsonpickle.loads(r\'\'\'{"endpoint": "127.0.0.1:9000", "console": "http://127.0.0.1:9001", "access_key": "admin", "secret_key": "password", "secure": false, "bucket_name": "my-bucket", "repo_key": null, "repo": null, "repo_type": "s3", "repo_prefix": "", "prefix": "", "storage_client": null, "extra_prefixes": []}\'\'\'))\nimport cloudpickle\nDuplicate = cloudpickle.loads(b\'\\x80\\x05\\x95\\x82&\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x17cloudpickle.cloudpickle\\x94\\x8c\\x14_make_skeleton_class\\x94\\x93\\x94(\\x8c\\x03abc\\x94\\x8c\\x07ABCMeta\\x94\\x93\\x94\\x8c\\tDuplicate\\x94\\x8c\\x0fdflow.python.op\\x94\\x8c\\x02OP\\x94\\x93\\x94\\x85\\x94}\\x94\\x8c 13a6223c2bf840549085509f505f1540\\x94Nt\\x94R\\x94\\x8c\\x1ccloudpickle.cloudpickle_fast\\x94\\x8c\\x0f_class_setstate\\x94\\x93\\x94h\\x0e}\\x94(\\x8c\\n__module__\\x94\\x8c\\x08__main__\\x94\\x8c\\x08__init__\\x94h\\x00\\x8c\\x0e_make_function\\x94\\x93\\x94(h\\x00\\x8c\\r_builtin_type\\x94\\x93\\x94\\x8c\\x08CodeType\\x94\\x85\\x94R\\x94(K\\x01K\\x00K\\x00K\\x01K\\x01K\\x03C\\x06\\x97\\x00d\\x00S\\x00\\x94N\\x85\\x94)\\x8c\\x04self\\x94\\x85\\x94\\x8cN/var/folders/v7/0mwcqlzd0c56flv47rkmgwj80000gp/T/ipykernel_95080/1903293247.py\\x94h\\x15\\x8c\\x12Duplicate.__init__\\x94K\\x02C\\x07\\x80\\x00\\xd8\\x08\\x0c\\x88\\x04\\x94C\\x00\\x94))t\\x94R\\x94}\\x94(\\x8c\\x0b__package__\\x94N\\x8c\\x08__name__\\x94h\\x14uNNNt\\x94R\\x94h\\x0f\\x8c\\x12_function_setstate\\x94\\x93\\x94h+}\\x94}\\x94(h)h\\x15\\x8c\\x0c__qualname__\\x94h"\\x8c\\x0f__annotations__\\x94}\\x94\\x8c\\x0e__kwdefaults__\\x94N\\x8c\\x0c__defaults__\\x94Nh\\x13h\\x14\\x8c\\x07__doc__\\x94N\\x8c\\x0b__closure__\\x94N\\x8c\\x17_cloudpickle_submodules\\x94]\\x94\\x8c\\x0b__globals__\\x94}\\x94u\\x86\\x94\\x86R0\\x8c\\x0eget_input_sign\\x94\\x8c\\x08builtins\\x94\\x8c\\x0bclassmethod\\x94\\x93\\x94h\\x17(h\\x1c(K\\x01K\\x00K\\x00K\\x01K\\x05K\\x03CT\\x97\\x00t\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x01\\x9c\\x02\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00S\\x00\\x94N\\x8c\\x06in_art\\x94\\x8c\\x06in_num\\x94\\x86\\x94\\x86\\x94(\\x8c\\x08OPIOSign\\x94\\x8c\\x08Artifact\\x94\\x8c\\x04Path\\x94\\x8c\\x03int\\x94t\\x94\\x8c\\x03cls\\x94\\x85\\x94h!h<\\x8c\\x18Duplicate.get_input_sign\\x94K\\x05C*\\x80\\x00\\xe5\\x0f\\x17\\xdd\\x16\\x1e\\x9dt\\x91n\\x94n\\xdd\\x16\\x19\\xf0\\x05\\x03\\x19\\n\\xf0\\x00\\x03\\x19\\n\\xf1\\x00\\x03\\x10\\x0b\\xf4\\x00\\x03\\x10\\x0b\\xf0\\x00\\x03\\t\\x0b\\x94h$))t\\x94R\\x94h\\\'NNNt\\x94R\\x94h-hQ}\\x94}\\x94(h)h<h0hLh1}\\x94h3Nh4Nh\\x13h\\x14h5Nh6Nh7]\\x94h9}\\x94(hE\\x8c\\x11dflow.python.opio\\x94hE\\x93\\x94hFhWhF\\x93\\x94hG\\x8c\\x07pathlib\\x94hG\\x93\\x94uu\\x86\\x94\\x86R0\\x85\\x94R\\x94\\x8c\\x0fget_output_sign\\x94h?h\\x17(h\\x1c(K\\x01K\\x00K\\x00K\\x01K\\x05K\\x03CT\\x97\\x00t\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\x06\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x01\\x9c\\x02\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00S\\x00\\x94N\\x8c\\x07out_art\\x94\\x8c\\x07out_num\\x94\\x86\\x94\\x86\\x94hIhJ\\x85\\x94h!h_\\x8c\\x19Duplicate.get_output_sign\\x94K\\x0cC*\\x80\\x00\\xe5\\x0f\\x17\\xdd\\x17\\x1f\\xa5\\x04\\x91~\\x94~\\xdd\\x17\\x1a\\xf0\\x05\\x03\\x19\\n\\xf0\\x00\\x03\\x19\\n\\xf1\\x00\\x03\\x10\\x0b\\xf4\\x00\\x03\\x10\\x0b\\xf0\\x00\\x03\\t\\x0b\\x94h$))t\\x94R\\x94h\\\'NNNt\\x94R\\x94h-hk}\\x94}\\x94(h)h_h0hfh1}\\x94h3Nh4Nh\\x13h\\x14h5Nh6Nh7]\\x94h9}\\x94(hEhXhFhYhGh[uu\\x86\\x94\\x86R0\\x85\\x94R\\x94\\x8c\\x07execute\\x94h\\x17(h\\x1c(K\\x02K\\x00K\\x00K\\x03K\\x05K\\x13C\\xd8\\x95\\x01\\x97\\x00t\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa0\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x01|\\x00\\xa0\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa6\\x00\\x00\\x00\\xab\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x01\\xa6\\x03\\x00\\x00\\xab\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x02\\x00\\x89\\x03|\\x00|\\x01\\xa6\\x02\\x00\\x00\\xab\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x02t\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa0\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x02|\\x00\\xa0\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa6\\x00\\x00\\x00\\xab\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x02\\xa6\\x03\\x00\\x00\\xab\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00|\\x02S\\x00\\x94N\\x88\\x89\\x87\\x94(h\\x08\\x8c\\x10_check_signature\\x94h<h_t\\x94h\\x1f\\x8c\\x05op_in\\x94\\x8c\\x06op_out\\x94\\x87\\x94\\x8cE/Users/star/anaconda3/lib/python3.11/site-packages/dflow/python/op.py\\x94\\x8c\\x0cwrapper_exec\\x94\\x8c(OP.exec_sign_check.<locals>.wrapper_exec\\x94K\\x85Ca\\xf8\\x80\\x00\\xe5\\x0c\\x0e\\xd7\\x0c\\x1f\\xd2\\x0c\\x1f\\xa0\\x05\\xa0t\\xd7\\\':\\xd2\\\':\\xd1\\\'<\\xd4\\\'<\\xb8d\\xd1\\x0cC\\xd4\\x0cC\\xd0\\x0cC\\xd8\\x15\\x19\\x90T\\x98$\\xa0\\x05\\xd1\\x15&\\xd4\\x15&\\x88F\\xdd\\x0c\\x0e\\xd7\\x0c\\x1f\\xd2\\x0c\\x1f\\xa0\\x06\\xa8\\x04\\xd7(<\\xd2(<\\xd1(>\\xd4(>\\xc0\\x05\\xd1\\x0cF\\xd4\\x0cF\\xd0\\x0cF\\xd8\\x13\\x19\\x88M\\x94h$\\x8c\\x04func\\x94\\x85\\x94)t\\x94R\\x94}\\x94(h(\\x8c\\x0cdflow.python\\x94h)h\\x07\\x8c\\x08__file__\\x94\\x8cE/Users/star/anaconda3/lib/python3.11/site-packages/dflow/python/op.py\\x94uNNh\\x00\\x8c\\x10_make_empty_cell\\x94\\x93\\x94)R\\x94\\x85\\x94t\\x94R\\x94h-h\\x8d}\\x94\\x8c\\x0b__wrapped__\\x94h\\x17(h\\x1c(K\\x02K\\x00K\\x00K\\x05K\\x06K\\x03BZ\\x01\\x00\\x00\\x97\\x00t\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x01d\\x01\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x02\\xa6\\x02\\x00\\x00\\xab\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x005\\x00}\\x02|\\x02\\xa0\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa6\\x00\\x00\\x00\\xab\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x03d\\x00d\\x00d\\x00\\xa6\\x02\\x00\\x00\\xab\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00n\\x0b#\\x001\\x00s\\x04w\\x02x\\x03Y\\x00w\\x01\\x01\\x00Y\\x00\\x01\\x00\\x01\\x00t\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x03d\\x04\\xa6\\x02\\x00\\x00\\xab\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x005\\x00}\\x02|\\x02\\xa0\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x03d\\x05z\\x05\\x00\\x00\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00d\\x00d\\x00d\\x00\\xa6\\x02\\x00\\x00\\xab\\x02\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00n\\x0b#\\x001\\x00s\\x04w\\x02x\\x03Y\\x00w\\x01\\x01\\x00Y\\x00\\x01\\x00\\x01\\x00t\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00t\\t\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x06\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x01d\\x07\\x19\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x08z\\x05\\x00\\x00d\\t\\x9c\\x02\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00}\\x04|\\x04S\\x00\\x94(NhA\\x8c\\x01r\\x94\\x8c\\x07bar.txt\\x94\\x8c\\x01w\\x94K\\x03\\x8c\\x06bar.py\\x94hBK\\x02hct\\x94(\\x8c\\x04open\\x94\\x8c\\x04read\\x94\\x8c\\x05write\\x94\\x8c\\x04OPIO\\x94hGt\\x94(h\\x1fhy\\x8c\\x01f\\x94\\x8c\\x07content\\x94hzt\\x94h!ht\\x8c\\x11Duplicate.execute\\x94K\\x13B&\\x01\\x00\\x00\\x80\\x00\\xf5\\n\\x00\\x0e\\x12\\x90%\\x98\\x08\\x94/\\xa03\\xd1\\r\\\'\\xd4\\r\\\'\\xf0\\x00\\x01\\t\\x1f\\xa81\\xd8\\x16\\x17\\x97f\\x92f\\x91h\\x94h\\x88G\\xf0\\x03\\x01\\t\\x1f\\xf0\\x00\\x01\\t\\x1f\\xf0\\x00\\x01\\t\\x1f\\xf1\\x00\\x01\\t\\x1f\\xf4\\x00\\x01\\t\\x1f\\xf0\\x00\\x01\\t\\x1f\\xf0\\x00\\x01\\t\\x1f\\xf0\\x00\\x01\\t\\x1f\\xf0\\x00\\x01\\t\\x1f\\xf0\\x00\\x01\\t\\x1f\\xf0\\x00\\x01\\t\\x1f\\xf8\\xf8\\xf8\\xf0\\x00\\x01\\t\\x1f\\xf0\\x00\\x01\\t\\x1f\\xf0\\x00\\x01\\t\\x1f\\xf0\\x00\\x01\\t\\x1f\\xe5\\r\\x11\\x90)\\x98S\\xd1\\r!\\xd4\\r!\\xf0\\x00\\x01\\t!\\xa0Q\\xd8\\x0c\\r\\x8fG\\x8aG\\x90G\\x98a\\x91K\\xd1\\x0c \\xd4\\x0c \\xd0\\x0c \\xf0\\x03\\x01\\t!\\xf0\\x00\\x01\\t!\\xf0\\x00\\x01\\t!\\xf1\\x00\\x01\\t!\\xf4\\x00\\x01\\t!\\xf0\\x00\\x01\\t!\\xf0\\x00\\x01\\t!\\xf0\\x00\\x01\\t!\\xf0\\x00\\x01\\t!\\xf0\\x00\\x01\\t!\\xf0\\x00\\x01\\t!\\xf8\\xf8\\xf8\\xf0\\x00\\x01\\t!\\xf0\\x00\\x01\\t!\\xf0\\x00\\x01\\t!\\xf0\\x00\\x01\\t!\\xf5\\x06\\x00\\x12\\x16\\xdd\\x17\\x1b\\x98H\\x91~\\x94~\\xd8\\x17\\x1c\\x98X\\x94\\x7f\\xa8\\x11\\xd1\\x17*\\xf0\\x05\\x03\\x17\\n\\xf0\\x00\\x03\\x17\\n\\xf1\\x00\\x03\\x12\\x0b\\xf4\\x00\\x03\\x12\\x0b\\x88\\x06\\xf0\\x08\\x00\\x10\\x16\\x88\\r\\x94C\\x1e\\x97\\x158\\x03\\xb8\\x04<\\x07\\xbf\\x01<\\x07\\xc1\\x13\\x19A8\\x03\\xc18\\x04A<\\x07\\xc1?\\x01A<\\x07\\x94))t\\x94R\\x94h\\\'NNNt\\x94R\\x94h-h\\xa4}\\x94}\\x94(h)hth0h\\x9eh1}\\x94(hyhWh\\x99\\x93\\x94\\x8c\\x06return\\x94h\\xa8uh3Nh4Nh\\x13h\\x14h5Nh6Nh7]\\x94h9}\\x94(h\\x96h\\x17(h\\x1c(K\\x01K\\x00K\\x00K\\x03K\\x05K\\x0fCP\\x97\\x00|\\x00d\\x01v\\x00r\\x13t\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00d\\x02|\\x00\\x9b\\x00d\\x03\\x9d\\x03\\xa6\\x01\\x00\\x00\\xab\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x82\\x01t\\x03\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00|\\x00g\\x01|\\x01\\xa2\\x01R\\x00i\\x00|\\x02\\xa4\\x01\\x8e\\x01S\\x00\\x94(N(K\\x00K\\x01K\\x02\\x91\\x94\\x8c\\x1eIPython won\\\'t let you open fd=\\x94\\x8ci by default as it is likely to crash IPython. If you know what you are doing, you can use builtins\\\' open.\\x94t\\x94\\x8c\\nValueError\\x94\\x8c\\x07io_open\\x94\\x86\\x94\\x8c\\x04file\\x94\\x8c\\x04args\\x94\\x8c\\x06kwargs\\x94\\x87\\x94\\x8cS/Users/star/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\\x94\\x8c\\x0e_modified_open\\x94h\\xb9M\\x15\\x01CU\\x80\\x00\\xe0\\x07\\x0b\\x88y\\xd0\\x07\\x18\\xd0\\x07\\x18\\xdd\\x0e\\x18\\xf0\\x02\\x02\\r*\\xa8T\\xf0\\x00\\x02\\r*\\xf0\\x00\\x02\\r*\\xf0\\x00\\x02\\r*\\xf1\\x03\\x04\\x0f\\n\\xf4\\x00\\x04\\x0f\\n\\xf0\\x00\\x04\\t\\n\\xf5\\x0c\\x00\\x0c\\x13\\x904\\xd0\\x0b)\\x98$\\xd0\\x0b)\\xd0\\x0b)\\xd0\\x0b)\\xa0&\\xd0\\x0b)\\xd0\\x0b)\\xd0\\x04)\\x94h$))t\\x94R\\x94}\\x94(h(\\x8c\\x0cIPython.core\\x94h)\\x8c\\x1dIPython.core.interactiveshell\\x94h\\x86h\\xb8uNNNt\\x94R\\x94h-h\\xc1}\\x94h\\x8f\\x8c\\x02io\\x94\\x8c\\x04open\\x94\\x93\\x94s}\\x94(h)\\x8c\\x04open\\x94h0\\x8c\\x04open\\x94h1}\\x94h3Nh4Nh\\x13h\\xc3h5Xv\\x17\\x00\\x00Open file and return a stream.  Raise OSError upon failure.\\n\\nfile is either a text or byte string giving the name (and the path\\nif the file isn\\\'t in the current working directory) of the file to\\nbe opened or an integer file descriptor of the file to be\\nwrapped. (If a file descriptor is given, it is closed when the\\nreturned I/O object is closed, unless closefd is set to False.)\\n\\nmode is an optional string that specifies the mode in which the file\\nis opened. It defaults to \\\'r\\\' which means open for reading in text\\nmode.  Other common values are \\\'w\\\' for writing (truncating the file if\\nit already exists), \\\'x\\\' for creating and writing to a new file, and\\n\\\'a\\\' for appending (which on some Unix systems, means that all writes\\nappend to the end of the file regardless of the current seek position).\\nIn text mode, if encoding is not specified the encoding used is platform\\ndependent: locale.getencoding() is called to get the current locale encoding.\\n(For reading and writing raw bytes use binary mode and leave encoding\\nunspecified.) The available modes are:\\n\\n========= ===============================================================\\nCharacter Meaning\\n--------- ---------------------------------------------------------------\\n\\\'r\\\'       open for reading (default)\\n\\\'w\\\'       open for writing, truncating the file first\\n\\\'x\\\'       create a new file and open it for writing\\n\\\'a\\\'       open for writing, appending to the end of the file if it exists\\n\\\'b\\\'       binary mode\\n\\\'t\\\'       text mode (default)\\n\\\'+\\\'       open a disk file for updating (reading and writing)\\n========= ===============================================================\\n\\nThe default mode is \\\'rt\\\' (open for reading text). For binary random\\naccess, the mode \\\'w+b\\\' opens and truncates the file to 0 bytes, while\\n\\\'r+b\\\' opens the file without truncation. The \\\'x\\\' mode implies \\\'w\\\' and\\nraises an `FileExistsError` if the file already exists.\\n\\nPython distinguishes between files opened in binary and text modes,\\neven when the underlying operating system doesn\\\'t. Files opened in\\nbinary mode (appending \\\'b\\\' to the mode argument) return contents as\\nbytes objects without any decoding. In text mode (the default, or when\\n\\\'t\\\' is appended to the mode argument), the contents of the file are\\nreturned as strings, the bytes having been first decoded using a\\nplatform-dependent encoding or using the specified encoding if given.\\n\\nbuffering is an optional integer used to set the buffering policy.\\nPass 0 to switch buffering off (only allowed in binary mode), 1 to select\\nline buffering (only usable in text mode), and an integer > 1 to indicate\\nthe size of a fixed-size chunk buffer.  When no buffering argument is\\ngiven, the default buffering policy works as follows:\\n\\n* Binary files are buffered in fixed-size chunks; the size of the buffer\\n  is chosen using a heuristic trying to determine the underlying device\\\'s\\n  "block size" and falling back on `io.DEFAULT_BUFFER_SIZE`.\\n  On many systems, the buffer will typically be 4096 or 8192 bytes long.\\n\\n* "Interactive" text files (files for which isatty() returns True)\\n  use line buffering.  Other text files use the policy described above\\n  for binary files.\\n\\nencoding is the name of the encoding used to decode or encode the\\nfile. This should only be used in text mode. The default encoding is\\nplatform dependent, but any encoding supported by Python can be\\npassed.  See the codecs module for the list of supported encodings.\\n\\nerrors is an optional string that specifies how encoding errors are to\\nbe handled---this argument should not be used in binary mode. Pass\\n\\\'strict\\\' to raise a ValueError exception if there is an encoding error\\n(the default of None has the same effect), or pass \\\'ignore\\\' to ignore\\nerrors. (Note that ignoring encoding errors can lead to data loss.)\\nSee the documentation for codecs.register or run \\\'help(codecs.Codec)\\\'\\nfor a list of the permitted encoding error strings.\\n\\nnewline controls how universal newlines works (it only applies to text\\nmode). It can be None, \\\'\\\', \\\'\\\\n\\\', \\\'\\\\r\\\', and \\\'\\\\r\\\\n\\\'.  It works as\\nfollows:\\n\\n* On input, if newline is None, universal newlines mode is\\n  enabled. Lines in the input can end in \\\'\\\\n\\\', \\\'\\\\r\\\', or \\\'\\\\r\\\\n\\\', and\\n  these are translated into \\\'\\\\n\\\' before being returned to the\\n  caller. If it is \\\'\\\', universal newline mode is enabled, but line\\n  endings are returned to the caller untranslated. If it has any of\\n  the other legal values, input lines are only terminated by the given\\n  string, and the line ending is returned to the caller untranslated.\\n\\n* On output, if newline is None, any \\\'\\\\n\\\' characters written are\\n  translated to the system default line separator, os.linesep. If\\n  newline is \\\'\\\' or \\\'\\\\n\\\', no translation takes place. If newline is any\\n  of the other legal values, any \\\'\\\\n\\\' characters written are translated\\n  to the given string.\\n\\nIf closefd is False, the underlying file descriptor will be kept open\\nwhen the file is closed. This does not work when a file name is given\\nand must be True in that case.\\n\\nA custom opener can be used by passing a callable as *opener*. The\\nunderlying file descriptor for the file object is then obtained by\\ncalling *opener* with (*file*, *flags*). *opener* must return an open\\nfile descriptor (passing os.open as *opener* results in functionality\\nsimilar to passing None).\\n\\nopen() returns a file object whose type depends on the mode, and\\nthrough which the standard file operations such as reading and writing\\nare performed. When open() is used to open a file in a text mode (\\\'w\\\',\\n\\\'r\\\', \\\'wt\\\', \\\'rt\\\', etc.), it returns a TextIOWrapper. When used to open\\na file in a binary mode, the returned class varies: in read binary\\nmode, it returns a BufferedReader; in write binary and append binary\\nmodes, it returns a BufferedWriter, and in read/write mode, it returns\\na BufferedRandom.\\n\\nIt is also possible to use a string or bytearray as a file for both\\nreading and writing. For strings StringIO can be used like a file\\nopened in a text mode, and for bytes a BytesIO can be used like a file\\nopened in a binary mode.\\x94h6Nh7]\\x94h9}\\x94h\\xb2h\\xc5su\\x86\\x94\\x86R0h\\x99h\\xa8hGh[uu\\x86\\x94\\x86R0s}\\x94(h)hth0h\\x9eh1h\\xa7h3Nh4Nh\\x13h\\x14h5Nh6h\\x00\\x8c\\n_make_cell\\x94\\x93\\x94h\\xa4\\x85\\x94R\\x94\\x85\\x94h7]\\x94h9}\\x94h\\x08h\\tsu\\x86\\x94\\x86R0h5N\\x8c\\x13__abstractmethods__\\x94(\\x91\\x94\\x8c\\t_abc_impl\\x94]\\x94u}\\x94\\x86\\x94\\x86R0.\')\nimport os, sys, traceback, jsonpickle\nfrom dflow.python import OPIO, TransientError, FatalError\nfrom dflow.python.utils import handle_input_artifact, handle_input_parameter\nfrom dflow.python.utils import handle_output_artifact, handle_output_parameter, handle_lineage\nfrom __main__ import Duplicate\n\nop_obj = Duplicate()\nop_obj.key = \'{{=inputs.parameters.dflow_key}}\'\nif op_obj.key.startswith(\'{\'): op_obj.key = None\nop_obj.workflow_name = \'{{workflow.name}}\'\nif __name__ == \'__main__\':\n    input = OPIO()\n    input_sign = Duplicate.get_input_sign()\n    output_sign = Duplicate.get_output_sign()\n    input[\'in_art\'] = handle_input_artifact(\'in_art\', input_sign[\'in_art\'], None, r\'/tmp\', None, n_parts=None, keys_of_parts=None, prefix=None)\n    input[\'in_num\'] = handle_input_parameter(\'in_num\', r\'\'\'{{inputs.parameters.in_num}}\'\'\', input_sign[\'in_num\'], None, r\'/tmp\')\n    try:\n        output = op_obj.execute(input)\n    except TransientError:\n        traceback.print_exc()\n        sys.exit(1)\n    except FatalError:\n        traceback.print_exc()\n        sys.exit(2)\n    os.makedirs(r\'/tmp/outputs/parameters\', exist_ok=True)\n    os.makedirs(r\'/tmp/outputs/artifacts\', exist_ok=True)\n    handle_output_artifact(\'out_art\', output[\'out_art\'], output_sign[\'out_art\'], None, r\'/tmp\')\n    handle_output_parameter(\'out_num\', output[\'out_num\'], output_sign[\'out_num\'], None, r\'/tmp\')\n'}}], 'entrypoint': 'python-steps', 'arguments': {}, 'serviceAccountName': 'argo', 'podGC': {}}, 'status': {'startedAt': None, 'finishedAt': None}, 'id': 'python-lccm6', 'uid': 'ae5e6d1f-42ed-4656-b705-48449c4f8d7e'}



## Docker镜像-工作流内部环境新手指南

#### 较为简单的工作流环境可以由如下代码进行指定：
- Alphine Linux 轻量环境
```python
    template = ShellOPTemplate(
        name=[str],
        image="alpine:latest",
        script=[str]
        )
```
- Python原生环境 (此处设定版本表示与本地系统保持一致)
```python
    template = PythonOPTemplate(
        [pythom class name], 
        image = f"python:{sys.version_info.major}.{sys.version_info.minor}"
        )
```
- PyTorch 官方镜像
```python
    template = PythonOPTemplate(
        [pythom class name], 
        image = "pytorch/pytorch:latest"
        )
```
- Deepchem 官方镜像 (版本为2.4, 较为古老, 更新较慢, 推荐自行配置较新版本)
```python
    template = PythonOPTemplate(
        [pythom class name], 
        image = "deepchemio/deepchem"
        )
```

#### 个性化自定义配置方法请参考接下来介绍的方法。

### Option 1: Dockerfile配置

适用条件 (符合以下一条或多条): 
- 有现成的 dokerfile + requirements 文档
- 有较为明确的依赖项需求及其版本号
- 依赖项非常多且复杂, 手动逐一安装过于繁琐

#### **配置文件：**
```
demo
  |- app
    |- app.py
  |- dockerfile
  |- k8service.yml
  |- makefile
  |- requirements.txt
```

### Option 2: 基础镜像上安装其他库

#### Step1: Pull官方基础镜像:
根据需要，安装官方基础镜像。此处给出几个例子：
1. python原生环境 (python:[版本号])
以较为稳定的3.8为例：
```
    docker pull python:3.8
```
2. TensorFlow官方镜像 (tensorflow/tensorflow:[版本号])
```
docker pull tensorflow/tensorflow:latest
```
3. PyTorch官方镜像 (pytorch/pytorch:[版本号])
```
    docker pull pytorch/pytorch:latest
```

显示下载完成后, 可以输入指令检查当前镜像列表:
```
    docker images
```

#### Step 2: 在基础镜像内安装其他库, 或配置依赖项

- 运行基础镜像
以DeePMD-kit为例:
```
    docker run -it python:3.8 /bin/bash
    pip install deepmd-kit[gpu,cu11,lmp,ipi]
```
- 新建一个窗口, 保持旧窗口未关闭且未exit, 输入指令查看`CONTAINER ID`
```
    docker ps -a
```
- 将这个ID填入下列指令, 即可将装入deepmd-kit的镜像保存下来
```
    docker commit [CONTAINER ID] [REPOSITORY]:[TAG]
```

#### Step 3: 将制作好的镜像发布至Dockerhub
- 此步骤需要先登录Dockerhub账号, 新用户需移步 ![DockerHub官网](https://hub.docker.com/) 注册
```
    docker login
```
- 将镜像push至Dockerhub
```
    docker tag [CONTAINER ID] [Username]/[Repository]:[Tag]
```
此处`[Tag]`名可以随意自定义

#### 至此，自定义配置的docker镜像就已经配置完成, 可以将发布的image直接在workflow step中调用
例如:
```python
    Step(
        name="setup-and-load",
        template=PythonOPTemplate(
            ExampleClass,
            image="starliu714/python:deepmd",
            python_packages=package_list,
        ),
        artifacts={
            ...
        }
    )
```

## XgBoost预测小分子活性 (基于Dflow工作流套件PythonOPTemplate)


```python
# Infrastructure modules
from dflow import Step, Workflow, upload_artifact
from dflow.python import OP, OPIO, Artifact, OPIOSign, PythonOPTemplate, upload_packages
from pathlib import Path

# Scientific Computing modules
import sys, os, torch
import deepchem as dc
import xgboost as xgb
from deepchem.data import NumpyDataset, DiskDataset
```

### 总体上分为五步: 
- 1 上传smile数据集至worflow环境
- 2 smile转指纹
- 3 指纹数据集正则化
- 4 拟合、训练模型
- 5 预测分子性质/测试模型表现


```python
tr_dataset = upload_artifact("trainBBBP.csv")
te_dataset = upload_artifact("testBBBP.csv")
val_dataset = upload_artifact("validBBBP.csv")
```

### Step 0: SetupAndLoad


```python
class SetupAndLoad(OP):
    def __init__(self):
        pass

    @classmethod
    def get_input_sign(cls):
        return OPIOSign({
            "train_file": Artifact(Path),
            "test_file": Artifact(Path),
            "valid_file": Artifact(Path),
        })

    @classmethod
    def get_output_sign(cls):
        return OPIOSign({
            "train_dataset_dir": Artifact(Path), 
            "test_dataset_dir": Artifact(Path),
            "valid_dataset_dir": Artifact(Path),
        })

    @OP.exec_sign_check
    def execute(self, op_in: OPIO) -> OPIO:
        train_file_path = str(op_in["train_file"])
        test_file_path = str(op_in["test_file"])
        valid_file_path = str(op_in["valid_file"])

        smile_str = 'SMILES'
        loader = dc.data.CSVLoader(
            tasks=['targets'], feature_field=smile_str, 
            featurizer=dc.feat.CircularFingerprint(size=256))

        train_dataset = loader.create_dataset(train_file_path)
        test_dataset = loader.create_dataset(test_file_path)
        valid_dataset = loader.create_dataset(valid_file_path)

        # Use the data_dir attribute to get the directory where the dataset is stored
        op_out = OPIO({
            "train_dataset_dir": Path(train_dataset.data_dir),
            "test_dataset_dir": Path(test_dataset.data_dir),
            "valid_dataset_dir": Path(valid_dataset.data_dir),
        })
        return op_out
```

### Step 1: TransformData


```python
class TransformData(OP):
    def __init__(self):
        pass

    @classmethod
    def get_input_sign(cls):
        return OPIOSign({
            "train_dataset_dir": Artifact(Path),
            "test_dataset_dir": Artifact(Path),
            "valid_dataset_dir": Artifact(Path),
        })

    @classmethod
    def get_output_sign(cls):
        return OPIOSign({
            "transformed_train_dir": Artifact(Path),
            "transformed_test_dir": Artifact(Path),
            "transformed_valid_dir": Artifact(Path),
        })

    @OP.exec_sign_check
    def execute(self, op_in: OPIO) -> OPIO:
        # Access the dataset paths from the artifacts
        train_dataset_path = str(op_in["train_dataset_dir"])
        test_dataset_path = str(op_in["test_dataset_dir"])
        valid_dataset_path = str(op_in["valid_dataset_dir"])

        # Load datasets
        train_dataset = DiskDataset(train_dataset_path)
        test_dataset = DiskDataset(test_dataset_path)
        valid_dataset = DiskDataset(valid_dataset_path)

        # Apply transformations
        transformer = dc.trans.NormalizationTransformer(transform_y=True, dataset=train_dataset)
        transformed_train = transformer.transform(train_dataset)
        transformed_test = transformer.transform(test_dataset)
        transformed_valid = transformer.transform(valid_dataset)

        # Return the data_dir of transformed datasets as artifacts
        op_out = OPIO({
            "transformed_train_dir": Path(transformed_train.data_dir),
            "transformed_test_dir": Path(transformed_test.data_dir),
            "transformed_valid_dir": Path(transformed_valid.data_dir),
        })
        return op_out
```

### Step 2: Train the model


```python
class TrainModel(OP):
    def __init__(self):
        pass

    @classmethod
    def get_input_sign(cls):
        return OPIOSign({
            "transformed_train": Artifact(Path),
            "transformed_valid": Artifact(Path),
        })

    @classmethod
    def get_output_sign(cls):
        return OPIOSign({
            "model_path": Artifact(Path),
        })

    @OP.exec_sign_check
    def execute(self, op_in: OPIO) -> OPIO:
        # Load transformed datasets from the provided paths
        transformed_train = DiskDataset(op_in["transformed_train"])
        transformed_valid = DiskDataset(op_in["transformed_valid"])

        # Train model
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        xgb_model = xgb.XGBClassifier(
            n_estimators=100, 
            learning_rate=0.1, 
            tree_method='auto' if device.type == 'cuda' else 'hist'
        )
        print("Fitting model...")

        dc_model = dc.models.GBDTModel(xgb_model, mode="classification")
        dc_model.fit_with_eval(transformed_train, transformed_valid)

        # Save the trained model and return its path as an artifact
        model_path = str(os.getcwd())
        dc_model.save(model_path)

        op_out = OPIO({
            "model_path": model_path,
        })
        return op_out
```

### Step 4: Predict and Evaluate


```python
class EvaluateModel(OP):
    def __init__(self):
        pass

    @classmethod
    def get_input_sign(cls):
        return OPIOSign({
            "model": Artifact(Path),
            "transformed_test": Artifact(Path),
        })

    @classmethod
    def get_output_sign(cls):
        return OPIOSign({
            "evaluation_metrics": float,  # AUC score as a float
        })

    @OP.exec_sign_check
    def execute(self, op_in: OPIO) -> OPIO:
        model = op_in["model"]
        test_dataset = op_in["transformed_test"]

        # Assuming the model is a DeepChem model and test_dataset is a DeepChem dataset
        metric = dc.metrics.Metric(dc.metrics.roc_auc_score)
        evaluation_metrics = model.evaluate(test_dataset, [metric])

        # Extract the AUC score from the evaluation metrics
        auc_score = evaluation_metrics["roc_auc_score"]

        op_out = OPIO({
            "evaluation_metrics": auc_score,
        })
        return op_out
```

### Setup Workflow

#### Import src of additional packages
注意: 
1. Numpy必须在docker中预装, 其部分编译后的文件无法通过调用本地源代码获得
2. 建议本地调试环境与Step环境保持一致, 否则容易出现version imcompatible


```python
package_list = [
    # "/Users/star/anaconda3/lib/python3.11/site-packages/deepchem", # deepchem
    # "/Users/star/anaconda3/lib/python3.11/site-packages/xgboost", # xgboost
    # "/Users/star/anaconda3/lib/python3.11/site-packages/pandas", # pandas
    # "/Users/star/anaconda3/lib/python3.11/site-packages/pytz", # pytz
    # "/Users/star/anaconda3/lib/python3.11/site-packages/dateutil", # dateutil
    "/Users/star/anaconda3/lib/python3.11/site-packages/rdkit", # rdkit
]
```

#### Step Setting


```python
# Step 0: Setup and Load Data
step0 = Step(
    name="setup-and-load",
    template=PythonOPTemplate(
        SetupAndLoad,
        image="starliu714/python:deepchem",
        # python_packages=package_list,
    ),
    artifacts={
        "train_file": tr_dataset,
        "test_file": te_dataset,
        "valid_file": val_dataset,
    }
)

# Step 1: Transform Data
step1 = Step(
    name="transform-data",
    template=PythonOPTemplate(
        TransformData,
        image="starliu714/python:deepchem",
    ),
    artifacts={
        "train_dataset_dir": step0.outputs.artifacts["train_dataset_dir"],
        "test_dataset_dir": step0.outputs.artifacts["test_dataset_dir"],
        "valid_dataset_dir": step0.outputs.artifacts["valid_dataset_dir"],
    }
)

# Step 2: Train Model
# It should take the output of step1 as input
step2 = Step(
    name="train-model",
    template=PythonOPTemplate(
        TrainModel,
        image="starliu714/python:deepchem",
    ),
    artifacts={
        "transformed_train": step1.outputs.artifacts["transformed_train_dir"],
        "transformed_valid": step1.outputs.artifacts["transformed_valid_dir"],
    }
)

# Step 3: Evaluate Model
step3 = Step(
    name="evaluate-model",
    template=PythonOPTemplate(
        EvaluateModel,
        image="starliu714/python:deepchem",
        python_packages=package_list,
    ),
    artifacts={
        "model": step2.outputs.artifacts["model_path"],  # Model artifact from step2
        "transformed_test": step1.outputs.artifacts["transformed_test_dir"],  # Test dataset artifact from step1
    }
)
```

#### Create and submit workflow


```python
wf = Workflow(name="xgboost")
wf.add(step0)
wf.add(step1)
wf.add(step2)
wf.add(step3)
wf.submit()
```

提交成功会显示字样:
```
Workflow has been submitted (ID: xgboost-6f6zg, UID: 68c9d900-6405-47de-b0df-6cda841294f4)
Workflow link: https://127.0.0.1:[Port number]/workflows/argo/[Workflow Name]-[Submission ID]
```
直接点击或复制链接至浏览器即可进入Argo Workflow的控制面板(dashboard)进行实时监测。

## 使用Dflow进行AI模型预测的优势：

1. 降低了ArgoCD Workflow的使用门槛
2. 更加复杂的工作流的实现, 例如: DAG、循环工作流
3. 高屋建瓴的视角, 更直观地监测和设计 AI模型、高通量计算/筛选系统
4. 实时监测每一步状态, 中途提取运行过程中的"中间产物"或"副产物"

### 对Dflow的思考和建议：

1. 对Windows的更低门槛的入门教学、技术支持
2. 期待更为完善的使用指南
3. 更多实用案例
4. 更广泛的宣传
